06/09/2024 15:57:48 - WARNING - __main__ - Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
06/09/2024 15:57:49 - INFO - models.modeling_nbitlinear - load_pretrained: resized variant: torch.Size([1, 577, 768]) to torch.Size([1, 197, 768])
06/09/2024 15:57:49 - INFO - __main__ - activation_bits: 2
classifier: token
hidden_size: 768
patches:
  size: !!python/tuple
  - 16
  - 16
representation_size: null
transformer:
  attention_dropout_rate: 0.0
  dropout_rate: 0.1
  mlp_dim: 3072
  num_heads: 12
  num_layers: 12
weight_bits: 2

06/09/2024 15:57:49 - INFO - __main__ - Training parameters Namespace(name='2-2_cifar10', dataset='cifar10', model_type='ViT-B_16', pretrained_dir='/fs/nexus-scratch/vla/ViT_pretrained_checkpoints/ViT-B_16.npz', output_dir='/fs/nexus-scratch/vla/ViT_model_weights/2-2/cifar10', img_size=224, train_batch_size=128, eval_batch_size=64, eval_every=2000, learning_rate=0.03, weight_decay=0, num_steps=10000, decay_type='cosine', warmup_steps=500, max_grad_norm=1.0, local_rank=-1, seed=42, gradient_accumulation_steps=1, fp16=False, fp16_opt_level='O2', loss_scale=0, weight_bits=2, activation_bits=2, n_gpu=1, device=device(type='cuda'))
06/09/2024 15:57:49 - INFO - __main__ - Total Parameter: 	85.8M
/fs/nexus-scratch/vla/micromamba/envs/VIT/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
06/09/2024 15:57:51 - INFO - __main__ - ***** Running training *****
06/09/2024 15:57:51 - INFO - __main__ -   Total optimization steps = 10000
06/09/2024 15:57:51 - INFO - __main__ -   Instantaneous batch size per GPU = 128
06/09/2024 15:57:51 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 128
06/09/2024 15:57:51 - INFO - __main__ -   Gradient Accumulation steps = 1
weight_bits:2
activation_bits:2
load_pretrained: grid-size from 24 to 14
85.806346
Files already downloaded and verified
Files already downloaded and verified
Training (X / X Steps) (loss=X.X):   0%|| 0/391 [00:00<?, ?it/s]/fs/nexus-scratch/vla/micromamba/envs/VIT/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Training (1 / 10000 Steps) (loss=2.30258):   0%|| 0/391 [00:05<?, ?it/s]/fs/nexus-scratch/vla/micromamba/envs/VIT/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:271: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
Training (1 / 10000 Steps) (loss=2.30258):   0%|| 1/391 [00:05<37:04,  5.70s/it]Training (2 / 10000 Steps) (loss=2.30263):   0%|| 1/391 [00:07<37:04,  5.70s/it]Training (2 / 10000 Steps) (loss=2.30263):   1%|| 2/391 [00:07<20:24,  3.15s/it]Training (3 / 10000 Steps) (loss=2.30259):   1%|| 2/391 [00:08<20:24,  3.15s/it]Training (3 / 10000 Steps) (loss=2.30259):   1%|| 3/391 [00:08<15:05,  2.33s/it]Training (4 / 10000 Steps) (loss=2.30242):   1%|| 3/391 [00:09<15:05,  2.33s/it]Training (4 / 10000 Steps) (loss=2.30242):   1%|| 4/391 [00:09<12:35,  1.95s/it]Training (5 / 10000 Steps) (loss=2.30290):   1%|| 4/391 [00:11<12:35,  1.95s/it]Training (5 / 10000 Steps) (loss=2.30290):   1%|| 5/391 [00:11<11:11,  1.74s/it]Training (6 / 10000 Steps) (loss=2.30195):   1%|| 5/391 [00:12<11:11,  1.74s/it]Training (6 / 10000 Steps) (loss=2.30195):   2%|| 6/391 [00:12<10:18,  1.61s/it]Training (7 / 10000 Steps) (loss=2.30371):   2%|| 6/391 [00:13<10:18,  1.61s/it]Training (7 / 10000 Steps) (loss=2.30371):   2%|| 7/391 [00:13<09:46,  1.53s/it]Training (8 / 10000 Steps) (loss=2.30441):   2%|| 7/391 [00:15<09:46,  1.53s/it]Training (8 / 10000 Steps) (loss=2.30441):   2%|| 8/391 [00:15<09:25,  1.48s/it]Training (9 / 10000 Steps) (loss=2.30393):   2%|| 8/391 [00:16<09:25,  1.48s/it]Training (9 / 10000 Steps) (loss=2.30393):   2%|| 9/391 [00:16<09:10,  1.44s/it]Training (10 / 10000 Steps) (loss=2.30409):   2%|| 9/391 [00:17<09:10,  1.44s/it]Training (10 / 10000 Steps) (loss=2.30409):   3%|| 10/391 [00:17<09:00,  1.42s/it]Training (11 / 10000 Steps) (loss=2.30218):   3%|| 10/391 [00:19<09:00,  1.42s/it]Training (11 / 10000 Steps) (loss=2.30218):   3%|| 11/391 [00:19<08:53,  1.40s/it]Training (12 / 10000 Steps) (loss=2.30266):   3%|| 11/391 [00:20<08:53,  1.40s/it]Training (12 / 10000 Steps) (loss=2.30266):   3%|| 12/391 [00:20<08:47,  1.39s/it]Training (13 / 10000 Steps) (loss=2.30455):   3%|| 12/391 [00:22<08:47,  1.39s/it]Training (13 / 10000 Steps) (loss=2.30455):   3%|| 13/391 [00:22<08:43,  1.39s/it]Training (14 / 10000 Steps) (loss=2.30647):   3%|| 13/391 [00:23<08:43,  1.39s/it]Training (14 / 10000 Steps) (loss=2.30647):   4%|| 14/391 [00:23<08:40,  1.38s/it]Training (15 / 10000 Steps) (loss=2.30927):   4%|| 14/391 [00:24<08:40,  1.38s/it]Training (15 / 10000 Steps) (loss=2.30927):   4%|| 15/391 [00:24<08:36,  1.37s/it]Training (16 / 10000 Steps) (loss=2.30336):   4%|| 15/391 [00:26<08:36,  1.37s/it]Training (16 / 10000 Steps) (loss=2.30336):   4%|| 16/391 [00:26<08:35,  1.37s/it]Training (17 / 10000 Steps) (loss=2.30989):   4%|| 16/391 [00:27<08:35,  1.37s/it]Training (17 / 10000 Steps) (loss=2.30989):   4%|| 17/391 [00:27<08:33,  1.37s/it]Training (18 / 10000 Steps) (loss=2.31675):   4%|| 17/391 [00:28<08:33,  1.37s/it]Training (18 / 10000 Steps) (loss=2.31675):   5%|| 18/391 [00:28<08:30,  1.37s/it]Training (19 / 10000 Steps) (loss=2.30288):   5%|| 18/391 [00:30<08:30,  1.37s/it]Training (19 / 10000 Steps) (loss=2.30288):   5%|| 19/391 [00:30<08:27,  1.36s/it]Training (20 / 10000 Steps) (loss=2.30287):   5%|| 19/391 [00:31<08:27,  1.36s/it]Training (20 / 10000 Steps) (loss=2.30287):   5%|| 20/391 [00:31<08:26,  1.37s/it]Training (21 / 10000 Steps) (loss=2.30279):   5%|| 20/391 [00:32<08:26,  1.37s/it]Training (21 / 10000 Steps) (loss=2.30279):   5%|| 21/391 [00:32<08:23,  1.36s/it]Training (22 / 10000 Steps) (loss=2.30368):   5%|| 21/391 [00:34<08:23,  1.36s/it]Training (22 / 10000 Steps) (loss=2.30368):   6%|| 22/391 [00:34<08:21,  1.36s/it]Training (23 / 10000 Steps) (loss=2.30945):   6%|| 22/391 [00:35<08:21,  1.36s/it]Training (23 / 10000 Steps) (loss=2.30945):   6%|| 23/391 [00:35<08:21,  1.36s/it]Training (24 / 10000 Steps) (loss=2.31179):   6%|| 23/391 [00:37<08:21,  1.36s/it]Training (24 / 10000 Steps) (loss=2.31179):   6%|| 24/391 [00:37<08:20,  1.36s/it]Training (25 / 10000 Steps) (loss=2.30692):   6%|| 24/391 [00:38<08:20,  1.36s/it]Training (25 / 10000 Steps) (loss=2.30692):   6%|| 25/391 [00:38<08:19,  1.37s/it]Training (26 / 10000 Steps) (loss=2.29772):   6%|| 25/391 [00:39<08:19,  1.37s/it]Training (26 / 10000 Steps) (loss=2.29772):   7%|| 26/391 [00:39<08:18,  1.37s/it]Training (27 / 10000 Steps) (loss=2.31102):   7%|| 26/391 [00:41<08:18,  1.37s/it]Training (27 / 10000 Steps) (loss=2.31102):   7%|| 27/391 [00:41<08:15,  1.36s/it]Training (28 / 10000 Steps) (loss=2.31883):   7%|| 27/391 [00:42<08:15,  1.36s/it]Training (28 / 10000 Steps) (loss=2.31883):   7%|| 28/391 [00:42<08:14,  1.36s/it]Training (29 / 10000 Steps) (loss=2.30535):   7%|| 28/391 [00:43<08:14,  1.36s/it]Training (29 / 10000 Steps) (loss=2.30535):   7%|| 29/391 [00:43<08:11,  1.36s/it]Training (30 / 10000 Steps) (loss=2.31080):   7%|| 29/391 [00:45<08:11,  1.36s/it]Training (30 / 10000 Steps) (loss=2.31080):   8%|| 30/391 [00:45<08:10,  1.36s/it]Training (31 / 10000 Steps) (loss=2.30718):   8%|| 30/391 [00:46<08:10,  1.36s/it]Training (31 / 10000 Steps) (loss=2.30718):   8%|| 31/391 [00:46<08:10,  1.36s/it]Training (32 / 10000 Steps) (loss=2.30780):   8%|| 31/391 [00:47<08:10,  1.36s/it]Training (32 / 10000 Steps) (loss=2.30780):   8%|| 32/391 [00:47<08:07,  1.36s/it]Training (33 / 10000 Steps) (loss=2.29958):   8%|| 32/391 [00:49<08:07,  1.36s/it]Training (33 / 10000 Steps) (loss=2.29958):   8%|| 33/391 [00:49<08:07,  1.36s/it]Training (34 / 10000 Steps) (loss=2.32744):   8%|| 33/391 [00:50<08:07,  1.36s/it]Training (34 / 10000 Steps) (loss=2.32744):   9%|| 34/391 [00:50<08:06,  1.36s/it]Training (35 / 10000 Steps) (loss=2.30002):   9%|| 34/391 [00:52<08:06,  1.36s/it]Training (35 / 10000 Steps) (loss=2.30002):   9%|| 35/391 [00:52<08:04,  1.36s/it]Training (36 / 10000 Steps) (loss=2.29396):   9%|| 35/391 [00:53<08:04,  1.36s/it]Training (36 / 10000 Steps) (loss=2.29396):   9%|| 36/391 [00:53<08:03,  1.36s/it]Training (37 / 10000 Steps) (loss=2.31002):   9%|| 36/391 [00:54<08:03,  1.36s/it]Training (37 / 10000 Steps) (loss=2.31002):   9%|| 37/391 [00:54<08:01,  1.36s/it]Training (38 / 10000 Steps) (loss=2.31904):   9%|| 37/391 [00:56<08:01,  1.36s/it]Training (38 / 10000 Steps) (loss=2.31904):  10%|| 38/391 [00:56<08:00,  1.36s/it]Training (39 / 10000 Steps) (loss=2.31215):  10%|| 38/391 [00:57<08:00,  1.36s/it]Training (39 / 10000 Steps) (loss=2.31215):  10%|| 39/391 [00:57<08:00,  1.36s/it]Training (40 / 10000 Steps) (loss=2.29861):  10%|| 39/391 [00:58<08:00,  1.36s/it]Training (40 / 10000 Steps) (loss=2.29861):  10%|| 40/391 [00:58<07:59,  1.37s/it]Training (41 / 10000 Steps) (loss=2.32398):  10%|| 40/391 [01:00<07:59,  1.37s/it]Training (41 / 10000 Steps) (loss=2.32398):  10%|| 41/391 [01:00<07:58,  1.37s/it]Training (42 / 10000 Steps) (loss=2.30165):  10%|| 41/391 [01:01<07:58,  1.37s/it]Training (42 / 10000 Steps) (loss=2.30165):  11%|| 42/391 [01:01<07:57,  1.37s/it]Training (43 / 10000 Steps) (loss=2.30611):  11%|| 42/391 [01:02<07:57,  1.37s/it]Training (43 / 10000 Steps) (loss=2.30611):  11%|| 43/391 [01:02<07:56,  1.37s/it]Training (44 / 10000 Steps) (loss=2.32194):  11%|| 43/391 [01:04<07:56,  1.37s/it]Training (44 / 10000 Steps) (loss=2.32194):  11%|| 44/391 [01:04<07:55,  1.37s/it]Training (45 / 10000 Steps) (loss=2.29715):  11%|| 44/391 [01:05<07:55,  1.37s/it]Training (45 / 10000 Steps) (loss=2.29715):  12%|| 45/391 [01:05<07:52,  1.37s/it]Training (46 / 10000 Steps) (loss=2.30805):  12%|| 45/391 [01:07<07:52,  1.37s/it]Training (46 / 10000 Steps) (loss=2.30805):  12%|| 46/391 [01:07<07:51,  1.37s/it]Training (47 / 10000 Steps) (loss=2.31291):  12%|| 46/391 [01:08<07:51,  1.37s/it]Training (47 / 10000 Steps) (loss=2.31291):  12%|| 47/391 [01:08<07:51,  1.37s/it]Training (48 / 10000 Steps) (loss=2.30775):  12%|| 47/391 [01:09<07:51,  1.37s/it]Training (48 / 10000 Steps) (loss=2.30775):  12%|| 48/391 [01:09<07:50,  1.37s/it]Training (49 / 10000 Steps) (loss=2.33523):  12%|| 48/391 [01:11<07:50,  1.37s/it]Training (49 / 10000 Steps) (loss=2.33523):  13%|| 49/391 [01:11<07:48,  1.37s/it]Training (50 / 10000 Steps) (loss=2.31383):  13%|| 49/391 [01:12<07:48,  1.37s/it]Training (50 / 10000 Steps) (loss=2.31383):  13%|| 50/391 [01:12<07:46,  1.37s/it]Training (51 / 10000 Steps) (loss=2.27289):  13%|| 50/391 [01:13<07:46,  1.37s/it]Training (51 / 10000 Steps) (loss=2.27289):  13%|| 51/391 [01:13<07:44,  1.37s/it]Training (52 / 10000 Steps) (loss=2.34684):  13%|| 51/391 [01:15<07:44,  1.37s/it]Training (52 / 10000 Steps) (loss=2.34684):  13%|| 52/391 [01:15<07:42,  1.36s/it]Training (53 / 10000 Steps) (loss=2.29588):  13%|| 52/391 [01:16<07:42,  1.36s/it]Training (53 / 10000 Steps) (loss=2.29588):  14%|| 53/391 [01:16<07:41,  1.37s/it]Training (54 / 10000 Steps) (loss=2.28480):  14%|| 53/391 [01:18<07:41,  1.37s/it]Training (54 / 10000 Steps) (loss=2.28480):  14%|| 54/391 [01:18<07:41,  1.37s/it]Training (55 / 10000 Steps) (loss=2.30591):  14%|| 54/391 [01:19<07:41,  1.37s/it]Training (55 / 10000 Steps) (loss=2.30591):  14%|| 55/391 [01:19<07:40,  1.37s/it]Training (56 / 10000 Steps) (loss=2.29404):  14%|| 55/391 [01:20<07:40,  1.37s/it]Training (56 / 10000 Steps) (loss=2.29404):  14%|| 56/391 [01:20<07:39,  1.37s/it]Training (57 / 10000 Steps) (loss=2.30272):  14%|| 56/391 [01:22<07:39,  1.37s/it]Training (57 / 10000 Steps) (loss=2.30272):  15%|| 57/391 [01:22<07:38,  1.37s/it]Training (58 / 10000 Steps) (loss=2.28207):  15%|| 57/391 [01:23<07:38,  1.37s/it]Training (58 / 10000 Steps) (loss=2.28207):  15%|| 58/391 [01:23<07:35,  1.37s/it]Training (59 / 10000 Steps) (loss=2.33749):  15%|| 58/391 [01:24<07:35,  1.37s/it]Training (59 / 10000 Steps) (loss=2.33749):  15%|| 59/391 [01:24<07:34,  1.37s/it]Training (60 / 10000 Steps) (loss=2.30670):  15%|| 59/391 [01:26<07:34,  1.37s/it]Training (60 / 10000 Steps) (loss=2.30670):  15%|| 60/391 [01:26<07:34,  1.37s/it]Training (61 / 10000 Steps) (loss=2.32499):  15%|| 60/391 [01:27<07:34,  1.37s/it]Training (61 / 10000 Steps) (loss=2.32499):  16%|| 61/391 [01:27<07:33,  1.37s/it]Training (62 / 10000 Steps) (loss=2.32625):  16%|| 61/391 [01:29<07:33,  1.37s/it]Training (62 / 10000 Steps) (loss=2.32625):  16%|| 62/391 [01:29<07:32,  1.38s/it]Training (63 / 10000 Steps) (loss=2.30716):  16%|| 62/391 [01:30<07:32,  1.38s/it]Training (63 / 10000 Steps) (loss=2.30716):  16%|| 63/391 [01:30<07:31,  1.38s/it]Training (64 / 10000 Steps) (loss=2.30140):  16%|| 63/391 [01:31<07:31,  1.38s/it]Training (64 / 10000 Steps) (loss=2.30140):  16%|| 64/391 [01:31<07:28,  1.37s/it]Training (65 / 10000 Steps) (loss=2.30307):  16%|| 64/391 [01:33<07:28,  1.37s/it]Training (65 / 10000 Steps) (loss=2.30307):  17%|| 65/391 [01:33<07:26,  1.37s/it]Training (66 / 10000 Steps) (loss=2.32356):  17%|| 65/391 [01:34<07:26,  1.37s/it]Training (66 / 10000 Steps) (loss=2.32356):  17%|| 66/391 [01:34<07:25,  1.37s/it]Training (67 / 10000 Steps) (loss=2.33002):  17%|| 66/391 [01:35<07:25,  1.37s/it]Training (67 / 10000 Steps) (loss=2.33002):  17%|| 67/391 [01:35<07:24,  1.37s/it]Training (68 / 10000 Steps) (loss=2.29681):  17%|| 67/391 [01:37<07:24,  1.37s/it]Training (68 / 10000 Steps) (loss=2.29681):  17%|| 68/391 [01:37<07:23,  1.37s/it]Training (69 / 10000 Steps) (loss=2.32668):  17%|| 68/391 [01:38<07:23,  1.37s/it]Training (69 / 10000 Steps) (loss=2.32668):  18%|| 69/391 [01:38<07:21,  1.37s/it]