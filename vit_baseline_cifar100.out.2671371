06/07/2024 13:09:47 - WARNING - __main__ - Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
06/07/2024 13:09:48 - INFO - models.modeling - load_pretrained: resized variant: torch.Size([1, 577, 768]) to torch.Size([1, 197, 768])
06/07/2024 13:09:48 - INFO - __main__ - classifier: token
hidden_size: 768
patches:
  size: !!python/tuple
  - 16
  - 16
representation_size: null
transformer:
  attention_dropout_rate: 0.0
  dropout_rate: 0.1
  mlp_dim: 3072
  num_heads: 12
  num_layers: 12

06/07/2024 13:09:48 - INFO - __main__ - Training parameters Namespace(name='baseline', dataset='cifar100', model_type='ViT-B_16', pretrained_dir='/fs/nexus-scratch/vla/ViT_pretrained_checkpoints/ViT-B_16.npz', output_dir='output', img_size=224, train_batch_size=256, eval_batch_size=64, eval_every=2000, learning_rate=0.03, weight_decay=0, num_steps=25000, decay_type='cosine', warmup_steps=500, max_grad_norm=1.0, local_rank=-1, seed=42, gradient_accumulation_steps=1, fp16=False, fp16_opt_level='O2', loss_scale=0, n_gpu=1, device=device(type='cuda'))
06/07/2024 13:09:48 - INFO - __main__ - Total Parameter: 	85.9M
