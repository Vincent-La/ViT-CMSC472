{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbff5ef5-c4e0-408d-a48c-a4abb3fb9a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from models.modeling_nbitlinear import VisionTransformer, CONFIGS\n",
    "import torch\n",
    "import numpy as np\n",
    "from models.nbitlinear import NBitLinear, quant\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed08e47d-0146-49a2-8e7f-f2bffa4720f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 11 20:23:45 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.78                 Driver Version: 550.78         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A4000               Off |   00000000:41:00.0 Off |                  Off |\n",
      "| 41%   36C    P2             36W /  140W |     546MiB /  16376MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   1697375      C   /nfshomes/elau1/ViT/bin/python3               540MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "037ff7ab-e454-446f-92db-3589cc1688d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f2d46f9-544c-4ee7-a4c7-306ad91c34e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"attention_data\", exist_ok=True)\n",
    "if not os.path.isfile(\"attention_data/ilsvrc2012_wordnet_lemmas.txt\"):\n",
    "    urlretrieve(\"https://storage.googleapis.com/bit_models/ilsvrc2012_wordnet_lemmas.txt\", \"attention_data/ilsvrc2012_wordnet_lemmas.txt\")\n",
    "if not os.path.isfile(\"attention_data/ViT-B_16-224.npz\"):\n",
    "    urlretrieve(\"https://storage.googleapis.com/vit_models/imagenet21k+imagenet2012/ViT-B_16-224.npz\", \"attention_data/ViT-B_16-224.npz\")\n",
    "\n",
    "imagenet_labels = dict(enumerate(open('attention_data/ilsvrc2012_wordnet_lemmas.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74df3df0-364c-4c8c-be5f-d27c2e36c704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (transformer): Transformer(\n",
       "    (embeddings): Embeddings(\n",
       "      (patch_embeddings): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x Block(\n",
       "          (attention_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (ffn_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (ffn): Mlp(\n",
       "            (fc1): NBitLinear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): NBitLinear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (attn): Attention(\n",
       "            (query): NBitLinear(in_features=768, out_features=768, bias=True)\n",
       "            (key): NBitLinear(in_features=768, out_features=768, bias=True)\n",
       "            (value): NBitLinear(in_features=768, out_features=768, bias=True)\n",
       "            (out): NBitLinear(in_features=768, out_features=768, bias=True)\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (proj_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (encoder_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_path = 'attention_data/ViT-B_16-224.npz'\n",
    "\n",
    "config = CONFIGS[\"ViT-B_16\"]\n",
    "config['weight_bits'] = 2\n",
    "config['activation_bits'] = 2\n",
    "\n",
    "model = VisionTransformer(config, num_classes=1000, zero_head=False, img_size=224, vis=False).to(device)\n",
    "model.load_from(np.load(pretrained_path))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed294f36-bfa4-4090-a190-79679001eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=256, interpolation=PIL.Image.BILINEAR),\n",
    "    transforms.CenterCrop(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "imagenet = datasets.ImageFolder(root=\"/fs/vulcan-datasets/imagenet/val\", transform=transform)\n",
    "imagenet_loader = DataLoader(dataset=imagenet, batch_size=batch_size, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1212033-c84b-4260-ae8d-669fd40e5e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.001\n"
     ]
    }
   ],
   "source": [
    "global_acc = 0\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(imagenet_loader):\n",
    "        images = images.to(device)\n",
    "        logits, _ = model(images)\n",
    "\n",
    "        for idx, image_logits in enumerate(logits):\n",
    "            probs = torch.nn.Softmax(dim=-1)(image_logits)\n",
    "            sorted_probs = torch.argsort(probs, dim=-1, descending=True)\n",
    "                    \n",
    "            y_hat_index = sorted_probs[0].item()\n",
    "            y_hat = imagenet_labels[y_hat_index]\n",
    "                    \n",
    "            y_index = labels[idx].item()\n",
    "            y = imagenet_labels[y_index]\n",
    "                    \n",
    "            if y_hat == y:\n",
    "                global_acc += 1\n",
    "\n",
    "global_acc /= len(imagenet_loader.dataset)\n",
    "print(f\"acc: {global_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc7715b-84c6-469a-b94e-270f22f310e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
